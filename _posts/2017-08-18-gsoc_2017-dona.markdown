---
title: Holmes Automated Malware Relationships
subtitle: Defining and Modeling Relationships
layout: default
modal-id: 6
category: gsoc2017
date: 2017-08-25
img: mal1.svg
thumbnail: mal1.svg
alt: license-img
repository: https://github.com/cli0/gsoc_relationship
documentation: https://github.com/cli0/gsoc_relationship/blob/primary_relationships/README.md
license: https://github.com/cli0/gsoc_relationship/blob/master/LICENSE

---

### About me

My name is Donika Mirdita. Currently, I am a full-time masters student at the Technical University of Munich, but sometimes I moonlight as an amateur security and machine learning researcher. My areas of interest are IT Security, Machine Learning and Distributed Systems. I love server farms, Big Data technology, playing with Apache projects and everything open source. I really dislike slow vpn connections and internet lag. I participated in Google Summer of Code for the Year 2017 and this blog post details the results of my work.

### 1. Project Overview

The project topic "Holmes Automated Malware Relationships" aims to generate scored malware
relationships by using malware analytic results as generated by [Holmes-Totem](https://github.com/HolmesProcessing/Holmes-Totem) and [Holmes-Totem-Dynamic](https://github.com/HolmesProcessing/Holmes-Totem-Dynamic). This major topic was split between me and another GSoC participant.

The purpose of my project is to :
1. define the concepts and components of a malware relationship
2. model the storage for this information  
3. efficiently leverage Spark and Cassandra to run large scale malware data analytics
{: .text-left .spaced-list}

This project was developed as a service for [Holmes Processing](https://github.com/HolmesProcessing) and it is designed to efficiently use the data and infrastructure as provided by this system. However, the ideas, concepts and models can be adapted on any system that wants to model malware relationships.

### 2. Documentation

##### 2.1 Defining Malware Relationships

Defining and scoring malware relationships in a Big Data environment requires a two stage process:

1. Stage 1 for extracting and pre-processing malware features of interest
2. Stage 2 to utilize the data from Stage 1 for final relationships generation and scoring
{: .text-left .spaced-list}

During this project, I wrote the code and set up the environment for running Stage 1.
In stage 1, I look for meaningful connections between artifacts based on specific feature. I determine meaningful similarities
by going over existing research, as well as by analyzing the data available in our Zoo. However, at this stage of the process, these connections are still too raw to be considered
proper final relationships. As a result, I use the term `primary relationship` for all the object pairs that my system generates.

##### 2.2 What is Stage 1 for?

Intelligent analytic systems are now part of the Big Data ecosystem. Meaningful detection systems need to be able to handle large volumes of data quickly and efficiently to satisfy client requests. As a result, analytic processes that are initiated by the client require (ideally) pre-processed, compact and easily queried data sources. Our analytic content (as generated by Totem), while very well organized, is not good enough for handling analytics on the fly. The tables can contain millions of entries, the results themselves can be large and therefore heavy, and the table format does not support fast feature extraction queries. This is not ideal if we want fast analytics. In Stage 1, I define the most important features for each object and available analytic service, and store these features so that they are both easily queried and do not restrict the analyst on the type of processes and analytics he wants to build. Stage 1 is comprised of batch processes that update the content of the analytics knowledge base periodically and asynchronously from client requests.

##### 2.3 Primary Relationships

There are 4 potential types of artifacts in our database: IP Addresses, Domains, Files, and Binary Executables. All of these artifact, despite their different formats, can have
meaningful connections or `relationships` with one another.

For example: A malicious executable may issue a call to a specific domain associated with one or more IPs. In turn, these IPs might be related to some bot campaign. Assuming these connections can be detected in your Zoo in some form, you have already identified several primary relationships:

1. Executable_1 <-> Domain_2

2. Domain_2 <-> IP_3

3. Executable_1 <-> IP_3

Each of the described connections above is a valid primary relationship. However, the disclaimer in the previous section remains: the primary relationships do not automatically map to final relationships. Primary relationships can also be circumstancial, and that is fine. Historical analytic records should never be deleted (unless they have a specific Time To Live threshold) and circumstancial connections can also be used to generate historical time series.

##### 2.4 A Few Words On The Data

The data that I use for my analytics contains exclusively Totem results. Every object is uniquely identified by their sha256 hash and for each object, the system runs multiple analytic services. The system allows the existence of duplicate results for the same object and service, because for many services the results can change in time. This change can occur when the service itself is patched, expanded or improved; when antivirus signatures get updated etc.

##### 2.5 Implementation: Knowledge Base Generation

The service results contain a lot of data and not all of that data is necessary for meaningful analytics. In addition to that, I aim to organize the data in easily queryable and parsed pieces of information in order to avoid unnecessary parsing and filtering during a client request. As a result, I first create a Knowledge Base table which contains every feature of interest for each object and result in the database. This table does not ignore or filter duplicate results. The main purpose of this table is to be an authoritative and easily expandable repository for all the information relevant for analytics. The second purpose of this repository is to improve query time by forgoing the need for expensive parsing and searching for every relationship request. This table can be generated in bulk during service downtime, and as a result not burden a client wishing to calculate relationships with extra waiting time. The Knowledge Base entries have the following format:

```
analytics_knowledge_base
  - object_id text,
  - feature_type text,
  - feature_value blob,
  - timestamp timeuuid
```

The features of interest are manually defined, in this case by me through careful research. This set is by no means exhaustive and it can (and should) be extended by the analyst whenever relevant information for relationship detection is defined, either by academic research or practical explorations on your dataset. So far, my system uses the following features as indicators of relationships:

| Feature Type  | Service |
|------------ | ----------|
| imphash  | PEInfo |
| pehash | PEInfo |
| binary_signature | PEInfo |
| domain_requests | CUCKOO |
| yara_rules | Yara |
{: class="table"}


The Knowledge Base table stores the feature type and the relevant feature content too. Due to the potentially large size, the feature content (`feature_value`) is compressed with gzip, hence the blob type. I use a slightly modified version of the following [code](https://gist.github.com/owainlewis/1e7d1e68a6818ee4d50e) for de/compressing my data. The compression method in this repository is very fast, lightweight and incurs little to no speed penalties according to my tests.

Knowledge Base generation is a batch routine that requires a list of object IDs (sha256 hashes) as parameter. This routine can be initiated whenever the user wants to populate the table with new entries. Tests on our servers have proved my routine to be fairly efficient with the following performance:

```
100 hashes -> 7s
1,000 hashes -> 7s
10,000 hashes -> 23s
```

##### 2.6 Implementation: Primary Relationships Generation

Primary Relationships are initial aggregations of the Knowledge Base data in order to generate and store connections between objects based on the similarities of their feature values. More concretely, primary relationships store, for each and every object in the database, identifiers of other objects with whom they share a feature similarity. For this implementation, I did not take into account duplicate results for the same object and same service. In this case, I specifically picked the newest result per object per service to generate primary relationships.

The storage for Primary Relationships was inspired in part by [TitanDB]("https://www.slideshare.net/knowfrominfo/titan-big-graph-data-with-cassandra"). For each object and each of its feature types, the primary relationships generation routine looks for matches, assigns a weight to each match, and stores the weighted matches as a Json array:

{% highlight json %}
{
  {"sha256":<text>, "weight": <Double>},
  {"sha256":<text>, "weight": <Double>}
}
{% endhighlight %}

The weights for these primary relationships are defined depending on the feature type, existing external research and observations from the analyst. Features like imphash, pehash and binary_signature are atomic values. For an exact same match for imphash and pehash, I assign the weight of 0.5. These weights are arbitrary values coming from an analyst (here: me). After extensive statistical analysis of my results as well as [research](https://www.usenix.org/legacy/event/leet09/tech/full_papers/wicherski/wicherski_html/) of
[academic](https://www.fireeye.com/blog/threat-research/2014/01/tracking-malware-import-hashing.html) literature, I have found that objects that share these hashes have a considerable chance of being related one way or another. In my implementation, I chose to only look for exact matches and not cluster based on hashes. I have already experimented with clustering based on malware hashes and I found that for Big Data, this approach can generate a lot of noise for the final relationships.

Unlike the hashes, the binary_signature was rarely present in the PEInfo results. These signatures are important descriptive features and yet they are rarely extractable. For example, in one of our largest results table, I could find at most a couple of hundreds of results with a binary_signature from a total of >500,000 PEInfo results. This suggests a relatively strong connection for those rare instances that have their binary_signatures *and* match exactly to another sample's signature. As a result of these observations, I assign a weight of 1.0 for exact binary_signature matches. The rest of the features in my set, namely yara_rules and domain_requests, are sets of values (rules and urls respectively), and I use [Jaccard Similarity](https://en.wikipedia.org/wiki/Jaccard_index) to calculate the weight of a match.

##### 2.7 Storage

The following figure shows the storage schema for the data that I generate in my implementations. You can find the code for automatically generating these tables in your Cassandra installation in the `./storage/storage.py` script.

![storage_schema](./img/dona/storage.png)

|Table Name | Description |
|-----------|-------------|
|`analytics_knowledge_base`| stores the knowledge base content as described in Section 2.5 .|
| `analytics_mv_knowledge_base_by_feature` | is a [Materialized View](https://www.datastax.com/dev/blog/new-in-cassandra-3-0-materialized-views) (MV) of the previous table. This MV is necessary to enable and speed up queries for primary relationships generation.|
| `analytics_primary_relationships` | this table stores the primary relationships as described in Section 2.6 . This table can be [expanded](https://github.com/cli0/gsoc_relationship/blob/master/storage/README.md) for newly introduced features without having to recompute the existing content. |
{: class="table"}

### 3. Good Times, Hard Times

The experience that I gained while doing GSoC was extremely valuable. I had the chance to discuss with experts and get valuable insights on how to efficiently approach a problem, how to model my data, and how to make compromises between efficiency and accuracy. In retrospect, this may sound pretty straightforward and easy, but when you are a student thrown into a real-world data management environment, you may end up struggling for a while until you learn to let go of what's weighing you down (your biases). Performance improvement was also something that I had to struggle with during the project. Creating queries is easy, but one of the main goals of the project was to efficiently leverage the power of my cluster and database. I spent a lot of time improving my data modeling to make the queries as cheap as possible. My efforts were rewarded with a fast, scalable and almost linear querying performance.

GSoC was tough, but the good kind of tough. It is something that I would warmly recommend to anyone who wants to engage in the open source community, build something beautiful, and who likes to struggle for their reward.   

### 4. Future Work

This project was a first shot at developing an operating and efficient analytics routine and there are still many more things that can be done to improve and expand it.

1. The set of feature types needs to be expanded. This can happen either by introducing new services or by applying machine learning techniques to detect classes and similarities using some non-straightforward but promising service results such as [Richheader](https://github.com/HolmesProcessing/RichHeader-Service_Collection) and [Objdump](https://github.com/HolmesProcessing/Holmes-Totem/tree/master/src/main/scala/org/holmesprocessing/totem/services/objdump).

2. Yara can be a very powerful source of information for similarity and, depending on the level of rule scrutiny, it could even go so far as to provide the degree of that similarity. Weighing two yara results using Jaccard Similarity is the bare minimum one can do to calculate similarity. Not all rules are made equal. Depending on the inner conditions, some rules are more relevant than others. It may be of interest to look deeper into yara, the content of their rulesets and create a service that provides a more detailed yara similarity output. Depending on the quality of the rules and the accuracy of the results, such a system could even be a standalone final relationships generator for binaries.

3. My application needs to be integrated with a pipeline that automates the process for Knowledge Base and Primary Relationships generation. As it stands, [Holmes-Analytics](https://github.com/HolmesProcessing/Holmes-Analytics) is where my code needs to integrate after GSoC in order to be fully integrated in the Holmes ecosystem.

### 5. Conclusions

I managed to fulfill all of my main goals so I am happy with the results of my project. There is still room for expansion and further improvements, some of which I detailed in the previous section. However, barring future extensions, I think the current iteration of the project is very sound in terms of logic and the performance is probably the best that we can get with the current setup.

### Acknowledgements

GSoC was a great experience and this was in no small part due to my mentors. Thank you for your support and your input: George Webster, Huang Xiao, Ryan Harris, and Zachary Hanif. I had a great time doing this project.
